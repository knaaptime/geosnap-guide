[
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "The Geospatial Neighborhood Analysis Package",
    "section": "0.1 Installation",
    "text": "0.1 Installation\nThe recommended method for installing geosnap is with anaconda. To get started with the development version, clone this repository or download it manually then cd into the directory and run the following commands:\nconda env create -f environment.yml\nconda activate geosnap \npython setup.py develop\nThis will download the appropriate dependencies and install geosnap in its own conda environment."
  },
  {
    "objectID": "index.html#development",
    "href": "index.html#development",
    "title": "The Geospatial Neighborhood Analysis Package",
    "section": "0.2 Development",
    "text": "0.2 Development\ngeosnap development is hosted on github"
  },
  {
    "objectID": "index.html#bug-reports",
    "href": "index.html#bug-reports",
    "title": "The Geospatial Neighborhood Analysis Package",
    "section": "0.3 Bug reports",
    "text": "0.3 Bug reports\nTo search for or report bugs, please see geosnap’s issues"
  },
  {
    "objectID": "index.html#license-information",
    "href": "index.html#license-information",
    "title": "The Geospatial Neighborhood Analysis Package",
    "section": "0.4 License information",
    "text": "0.4 License information\nSee the file “LICENSE.txt” for information on the history of this software, terms & conditions for usage, and a DISCLAIMER OF ALL WARRANTIES."
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "The Geospatial Neighborhood Analysis Package",
    "section": "0.5 Citation",
    "text": "0.5 Citation\nFor a generic citation of geosnap, we recommend the following:\n@misc{Knaap2019,\nauthor = {Knaap, Elijah and Kang, Wei and Rey, Sergio and Wolf, Levi John and Cortes, Renan Xavier and Han, Su},\ndoi = {10.5281/ZENODO.3526163},\ntitle = {geosnap: The Geospatial Neighborhood Analysis Package},\nurl = {https://zenodo.org/record/3526163},\nyear = {2019}\n}\nIf you need to cite a specific release of the package, please find the appropriate version on Zenodo"
  },
  {
    "objectID": "index.html#funding",
    "href": "index.html#funding",
    "title": "The Geospatial Neighborhood Analysis Package",
    "section": "0.6 Funding",
    "text": "0.6 Funding\npegdgbk ../images/nsf_logo.jpg :alt: NSF :width: 100px\nThis project is supported by NSF Award #1733705, Neighborhoods in Space-Time Contexts"
  },
  {
    "objectID": "harmonization.html#original-data",
    "href": "harmonization.html#original-data",
    "title": "3  Boundary Harmonization",
    "section": "3.1 Original Data",
    "text": "3.1 Original Data\nFirst, we’ll create a new Community from San Diego county\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom geosnap import DataStore\nfrom geosnap import analyze as gaz\nfrom geosnap import io as gio\nfrom geosnap import visualize as gvz\nfrom geosnap.harmonize import harmonize\n\ndatasets = DataStore()\n\n\n%load_ext watermark\n%watermark -a 'eli knaap' -d -u -iv\n\nAuthor: eli knaap\n\nLast updated: 2024-01-16\n\npandas    : 2.1.4\ngeosnap   : 0.12.1.dev9+g3a1cb0f6de61.d20240110\nmatplotlib: 3.8.2\ngeopandas : 0.14.1\n\n\n\nUsing the from_census constructor, we’ll grab some original census data which by default, includes data from 1990, 2000, and 2010 and adjusts all currency columns for inflation by converting them into 2015 dollars (if you want to suppress this behavior set constant_dollars=False). Here’s how median contract has changed in San Diego county if we plot maps of the original boundaries\n\nsd = gio.get_census(datasets, county_fips=\"06073\", currency_year=2019)\n\n\nsd_acs = gio.get_acs(datasets, county_fips=\"06073\", years=[2020], level=\"tract\", currency_year=2019)\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/io/constructors.py:215: UserWarning: Currency columns unavailable at this resolution; not adjusting for inflation\n  warn(\n\n\n\nsd_acs = sd_acs.to_crs(6426)\n\n\nsd = sd.to_crs(6426)\n\n\nsd = gpd.GeoDataFrame(pd.concat([sd, sd_acs]))\n\nThere are several different harmonization techniques in the literature (for a deeper dive on spatial interpolation checkout the tobler library) but nearly all of them require good estimates of source and target polygon areas. That means it’s important to set a reasonable CRS for the study region (which should be a familiar habit anyway). In this case, epsg 6246 is appropriate\n\ngvz.plot_timeseries(\n    sd,\n    \"median_contract_rent\",\n    title=\"Median Rent, Original Boundaries\",\n    cmap=\"Greens\",\n    dpi=200,\n    figsize=(12, 12),\n    nrows=2,\n    ncols=2,\n)\nplt.tight_layout()\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/visualize/mapping.py:170: UserWarning: `proplot` is not installed.  Falling back to matplotlib\n  warn(\"`proplot` is not installed.  Falling back to matplotlib\")\n\n\n\n\n\nIt looks like San Diego county has gotten dramatically more expensive over time, particularly through the 2000s. But since the underlying geographic units are changing over time, we still can’t make tract-to-tract comparisons, so we can harmonize the boundaries. Here we’ll take each census year and convert population and median income data into constant boundaries from the 2020 census."
  },
  {
    "objectID": "harmonization.html#harmonization-using-areal-interpolation",
    "href": "harmonization.html#harmonization-using-areal-interpolation",
    "title": "3  Boundary Harmonization",
    "section": "3.2 Harmonization using Areal Interpolation",
    "text": "3.2 Harmonization using Areal Interpolation\nThe simplest way to harmonize boundaries is to use areal interpolation, meaning we use the area of overlap between consecutive years to create a weighted sum of intersecting polygons. This approach assumes each polygon has constant density of each attribute so its most useful when the polygons are small and homogenous\nWhen harmonizing boundaries over time, we need to distinguish between intensive and extensive variables because each needs to be handled differently during the interpolation process. Median income is a statistic (so intensive), whereas total population is a count (extensive), so we make sure to pass each to the appropriate list\n\nsd_harm20 = harmonize(\n    sd,\n    intensive_variables=[\"median_contract_rent\", \"p_hispanic_persons\"],\n    extensive_variables=[\"n_total_pop\"],\n    weights_method=\"area\",\n    target_year=2020,\n)\n\n/Users/knaaptime/mambaforge/envs/geosnap/lib/python3.11/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\n\n\ngvz.plot_timeseries(\n    sd_harm20,\n    \"median_contract_rent\",\n    title=\"Median Rent, 2010 Boundaries\",\n    cmap=\"Greens\",\n    dpi=200,\n    figsize=(12, 12),\n    nrows=2,\n    ncols=2,\n)\nplt.tight_layout()\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/visualize/mapping.py:170: UserWarning: `proplot` is not installed.  Falling back to matplotlib\n  warn(\"`proplot` is not installed.  Falling back to matplotlib\")\n\n\n\n\n\n\ngvz.plot_timeseries(\n    sd_harm20,\n    \"p_hispanic_persons\",\n    title=\"Hispanic Population (%), 2010 Boundaries\",\n    dpi=200,\n    figsize=(12, 12),\n    nrows=2,\n    ncols=2,\n)\nplt.tight_layout()\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/visualize/mapping.py:170: UserWarning: `proplot` is not installed.  Falling back to matplotlib\n  warn(\"`proplot` is not installed.  Falling back to matplotlib\")\n\n\n\n\n\nWe could also use 1990 boundaries as our target to see how the region has evolved according to those units:\n\nsd_harm90 = harmonize(\n    sd,\n    intensive_variables=[\"median_contract_rent\"],\n    weights_method=\"area\",\n    target_year=1990,\n)\n\ngvz.plot_timeseries(\n    sd_harm90,\n    \"median_contract_rent\",\n    title=\"Median Rent, 1990 Boundaries\",\n    cmap=\"Greens\",\n    dpi=200,\n    figsize=(12, 12),\n    nrows=2,\n    ncols=2,\n)\nplt.tight_layout()\n\n/Users/knaaptime/mambaforge/envs/geosnap/lib/python3.11/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/visualize/mapping.py:170: UserWarning: `proplot` is not installed.  Falling back to matplotlib\n  warn(\"`proplot` is not installed.  Falling back to matplotlib\")"
  },
  {
    "objectID": "harmonization.html#harmonization-using-dasymetric-interpolation",
    "href": "harmonization.html#harmonization-using-dasymetric-interpolation",
    "title": "3  Boundary Harmonization",
    "section": "3.3 Harmonization using Dasymetric Interpolation",
    "text": "3.3 Harmonization using Dasymetric Interpolation\nTo account for the fact that most variables are not distributed uniformly thoughout the polygon (e.g. development is often clustered rather than spread evenly throughout each census tract), geosnap can use dasymetric interpolation that incorporates additional information for a more accurate harmonization. In this case, we can use raster data like the NLCD to constrain our interpolation to only the developed part of each census tract.\noturns distributes an optimized version of the NLCD data through its quilt bucket for use in harmonization so we can download it simply using quilt. Since we’re harmonizing boundaries from the past, our auxiliary data should roughly match the time period of the polygon data we’re converting. The earliest version of the NLCD available is 2001, so we’ll use that\nTo use dasymetric harmonization, we need to change the weights_method and provide a path to a valid raster file (which, in this case, we just downloaded to th current dir). When using a raster file as a dasymetric mask, we need to tell the function which raster cells are part of the mask. In this case, the pixels in the NLCD raster to different land use types, and we want to constrain the interpolation to developed land. So here we’ll set the pixel_values argument to the developed land types from the nlcd:\n\n22 (Developed, Low Intensity)\n23 (Developed, Medium Intensity)\n24 (Developed, High Intensity)\n\nNote: dasymetric interpolation is much more data intensive so it takes considerably longer to calculate. On my machine it takes roughly 90 seconds per time period for this study area, whereas the pure areal interpolation completes in a few seconds each. Ninety seconds is still pretty impressive in this case, given that the raster file is ~1.5gb and is being read directly from the web.\n\nsd_harm10_dasy = harmonize(\n    sd,\n    intensive_variables=[\"median_contract_rent\"],\n    weights_method=\"dasymetric\",\n    raster=\"https://spatial-ucr.s3.amazonaws.com/nlcd/landcover/nlcd_landcover_2021.tif\",\n    pixel_values=[21, 22, 23, 24],\n    target_year=2010,\n)\n\n/Users/knaaptime/mambaforge/envs/geosnap/lib/python3.11/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\n\n/Users/knaaptime/mambaforge/envs/geosnap/lib/python3.11/site-packages/shapely/set_operations.py:131: RuntimeWarning: invalid value encountered in intersection\n  return lib.intersection(a, b, **kwargs)\n/Users/knaaptime/mambaforge/envs/geosnap/lib/python3.11/site-packages/shapely/set_operations.py:131: RuntimeWarning: invalid value encountered in intersection\n  return lib.intersection(a, b, **kwargs)\n/Users/knaaptime/mambaforge/envs/geosnap/lib/python3.11/site-packages/shapely/set_operations.py:131: RuntimeWarning: invalid value encountered in intersection\n  return lib.intersection(a, b, **kwargs)\n/Users/knaaptime/mambaforge/envs/geosnap/lib/python3.11/site-packages/shapely/set_operations.py:131: RuntimeWarning: invalid value encountered in intersection\n  return lib.intersection(a, b, **kwargs)\n/Users/knaaptime/mambaforge/envs/geosnap/lib/python3.11/site-packages/shapely/set_operations.py:131: RuntimeWarning: invalid value encountered in intersection\n  return lib.intersection(a, b, **kwargs)\n/Users/knaaptime/mambaforge/envs/geosnap/lib/python3.11/site-packages/shapely/set_operations.py:131: RuntimeWarning: invalid value encountered in intersection\n  return lib.intersection(a, b, **kwargs)\n/Users/knaaptime/mambaforge/envs/geosnap/lib/python3.11/site-packages/shapely/set_operations.py:131: RuntimeWarning: invalid value encountered in intersection\n  return lib.intersection(a, b, **kwargs)\n\n\n\ngvz.plot_timeseries(\n    sd_harm10_dasy,\n    \"median_contract_rent\",\n    title=\"Median Rent, 2010 Boundaries w/ Dasymetric Interpolation\",\n    dpi=200,\n    cmap=\"Greens\",\n    figsize=(12, 12),\n    nrows=2,\n    ncols=2,\n)\nplt.tight_layout()\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/visualize/mapping.py:170: UserWarning: `proplot` is not installed.  Falling back to matplotlib\n  warn(\"`proplot` is not installed.  Falling back to matplotlib\")\n\n\n\n\n\nThe NLCD is a useful dasymetric layer because it has high spatial resolution and classifies a relatively wide range of land uses. By constraining our interpolation to developed land uses we ensure that there are no variables allocated to obviously incorrect places like forests, lakes, or farms. But it doesnt do anything to prevent allocating variables to developed land uses that don’t have population–like heavy industry, airports, parking lots, or shopping malls. Depending on the particular problem and location, you may want to inclue or exclude different pixel types. There may also be better raster sources that could be used as alternatives"
  },
  {
    "objectID": "harmonization.html#harmonizing-to-an-alternate-geographic-unit",
    "href": "harmonization.html#harmonizing-to-an-alternate-geographic-unit",
    "title": "3  Boundary Harmonization",
    "section": "3.4 Harmonizing to an Alternate Geographic Unit",
    "text": "3.4 Harmonizing to an Alternate Geographic Unit\nIn some cases, it can be useful to discard the original boundaries altogether and instead harmonize all time periods to a consistent geographic unit defined elsewhere (like a school district, or congressional district, or a regular hexgrid)\n\nfrom tobler.util import h3fy\n\nNote you need the h3 libarary to run this cell, which might require mamba install hy-py\n\nsd_hex = h3fy(sd[sd.year == 2010], resolution=7)\n\n/Users/knaaptime/mambaforge/envs/geosnap/lib/python3.11/site-packages/pyproj/crs/crs.py:1293: UserWarning: You will likely lose important projection information when converting to a PROJ string from another format. See: https://proj.org/faq.html#what-is-the-best-format-for-describing-coordinate-reference-systems\n  proj = self._crs.to_proj4(version=version)\n\n\n\nsd_hex.plot()\n\n&lt;Axes: &gt;\n\n\n\n\n\n\nsd_hex_interp = harmonize(\n    sd, target_gdf=sd_hex, intensive_variables=[\"median_home_value\"]\n)\n\n\n\n\n\ngvz.plot_timeseries(\n    sd_hex_interp,\n    \"median_home_value\",\n    title=\"Median Home Value, Regular Hexgrid\",\n    dpi=200,\n    cmap=\"Greens\",\n    figsize=(12, 12),\n    nrows=2,\n    ncols=2,\n)\nplt.tight_layout()\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/visualize/mapping.py:170: UserWarning: `proplot` is not installed.  Falling back to matplotlib\n  warn(\"`proplot` is not installed.  Falling back to matplotlib\")"
  },
  {
    "objectID": "regionalization.html#cross-sectional-regionalization",
    "href": "regionalization.html#cross-sectional-regionalization",
    "title": "5  Geodemographic Regionalization",
    "section": "5.1 Cross-Sectional Regionalization",
    "text": "5.1 Cross-Sectional Regionalization\n\natl_kmeans_reg, atl_k_model = gaz.regionalize(\n    gdf=atl, method=\"kmeans_spatial\", n_clusters=5, columns=columns, return_model=True\n)\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/geodemo.py:406: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n  w0 = W.from_dataframe(df, **weights_kwargs)\n\n\n\natl_kmeans_reg[columns + [\"geometry\", \"kmeans_spatial\"]].explore(\n    \"kmeans_spatial\", categorical=True, cmap=\"Accent\", tiles=\"CartoDB Positron\"\n)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nUnlike the general clustering case, regionalization algorithrms\nTo understand what the clusters are identifying, another data visualisation technique is useful. Here, we rely on the Tufte-ian principle of “small multiples”, and create a set of violin plots that show how each variable is distributed across each of the clusters. Each of the inset boxes shows a different variable, with cluster assignments on the x-axis, and the variable itself on the y-axis The boxplot in the center shows the median and IQR, and the “body” of the “violin” is a kernel-density estimate reflected across the x-axis. In short, the fat parts of the violin show where the bulk of the observations are located, and the skinny “necks” show the long tails.\n\ngvz.plot_violins_by_cluster(atl_kmeans_reg, columns, cluster_col=\"kmeans_spatial\")\n\narray([&lt;Axes: title={'center': 'median_household_income'}, xlabel='kmeans_spatial', ylabel='median_household_income'&gt;,\n       &lt;Axes: title={'center': 'median_home_value'}, xlabel='kmeans_spatial', ylabel='median_home_value'&gt;,\n       &lt;Axes: title={'center': 'p_edu_college_greater'}, xlabel='kmeans_spatial', ylabel='p_edu_college_greater'&gt;,\n       &lt;Axes: title={'center': 'p_edu_hs_less'}, xlabel='kmeans_spatial', ylabel='p_edu_hs_less'&gt;,\n       &lt;Axes: title={'center': 'p_nonhisp_white_persons'}, xlabel='kmeans_spatial', ylabel='p_nonhisp_white_persons'&gt;,\n       &lt;Axes: title={'center': 'p_nonhisp_black_persons'}, xlabel='kmeans_spatial', ylabel='p_nonhisp_black_persons'&gt;,\n       &lt;Axes: title={'center': 'p_hispanic_persons'}, xlabel='kmeans_spatial', ylabel='p_hispanic_persons'&gt;,\n       &lt;Axes: title={'center': 'p_asian_persons'}, xlabel='kmeans_spatial', ylabel='p_asian_persons'&gt;,\n       &lt;Axes: &gt;], dtype=object)\n\n\n\n\n\nNotice here that the violin plots are much harder to distinguish. That is, by enforcing a contiguity constraint, many census tracts are grouped with other tracts that they are closest to, rather than those they are most similar to in multivariate attribute space. This is reflected in the silhouette scores as well.\nUnlike the general clustering case, regionalization algorithms return a dictionary of ModelResults classes (one for each unique time period in the dataset) because it is not possible to create a pooled regionalization solution using data from multiple time periods\n\natl_k_model\n\n{2021: &lt;geosnap.analyze._model_results.ModelResults at 0x2b4974b90&gt;}\n\n\n\natl_k_model[2021].plot_silhouette()\n\n&lt;Axes: title={'center': 'Silhouette Score'}, xlabel='Silhouette coefficient values', ylabel='Cluster label'&gt;\n\n\n\n\n\nThis is a poor silhouette score indeed–the overall score for the solution is negative, meaning most tracts are more similar (in attributes) to tracts in another cluster than the one they are assigned. But a silhouette score is not the ideal metric in this case, because attribute similarity is no longer the only objective the model is trying to achieve.\n\natl_k_model[2021].plot_silhouette_map(figsize=(9, 9))\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/visualize/mapping.py:170: UserWarning: `proplot` is not installed.  Falling back to matplotlib\n  warn(\"`proplot` is not installed.  Falling back to matplotlib\")\n\n\n[&lt;Axes: title={'center': '2021'}&gt;]\n\n\n\n\n\nRather than searching for unique types, regardless of where they are in the study area (which is what general clustering algorithms focus on), regionalization algorithms arguable search for unique places in the study area, where uniqueness is defined by the concentration of attribute similarity in space. That is, we are looking for places that are geographically distinct from their neighbors, where members of a single region are relatively similar to one another, but distinctly different from those nearby.\nTo operationalize these concepts, we leverage the notion of a geosilhouette, which blends the roles of geographic and attribute similarity into a single metric. There are two types of geosilhouettes, depending on whether we are most interested in differences between region cores (path silhouettes) or region boundaries (boundary silhouettes)\n\natl_k_model[2021].boundary_silhouette.boundary_silhouette.mean()\n\n0.04977250598127544\n\n\n\natl_k_model[2021].plot_boundary_silhouette(figsize=(8, 8))\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/visualize/mapping.py:170: UserWarning: `proplot` is not installed.  Falling back to matplotlib\n  warn(\"`proplot` is not installed.  Falling back to matplotlib\")\n/Users/knaaptime/mambaforge/envs/geosnap/lib/python3.11/site-packages/mapclassify/classifiers.py:1592: UserWarning: Not enough unique values in array to form 6 classes. Setting k to 4.\n  self.bins = quantile(y, k=k)\n\n\n[&lt;Axes: title={'center': '2021'}&gt;]\n\n\n\n\n\n\natl_k_model[2021].path_silhouette.path_silhouette.mean()\n\n-0.009141046038233335\n\n\n\natl_k_model[2021].plot_path_silhouette(figsize=(8, 8))\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/visualize/mapping.py:170: UserWarning: `proplot` is not installed.  Falling back to matplotlib\n  warn(\"`proplot` is not installed.  Falling back to matplotlib\")\n\n\n[&lt;Axes: title={'center': '2021'}&gt;]\n\n\n\n\n\nThere are also many regionalization algorithms to choose from (see the PySAL spopt package for more information on each of them)\n\ncluster_types = [\n    \"kmeans_spatial\",\n    \"ward_spatial\",\n    \"skater\",\n    \"spenc\",\n    \"azp\",\n    \"max_p\",\n]\n\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nf, ax = plt.subplots(2, 3, figsize=(15, 10))\nax = ax.flatten()\n\nfor i, k in enumerate(cluster_types):\n    df = gaz.regionalize(\n        gdf=atl,\n        method=k,\n        columns=columns,\n        n_clusters=10,\n        scaler=MinMaxScaler(),\n        weights_kwargs=dict(use_index=True)\n\n    )\n    df.to_crs(3857).sort_values(k).plot(k, categorical=True, figsize=(7, 7), ax=ax[i])\n    ax[i].axis(\"off\")\n    ax[i].set_title(k, fontsize=14)\n    ctx.add_basemap(ax=ax[i], source=ctx.providers.CartoDB.Positron)\n    plt.tight_layout()\n\nFloatingPointError: underflow encountered in exp\n\n\n\n\n\nNote that the colors do not mean anything when comparing across maps, only the patterns matter. Thus, even though the kmeans, ward, and affinity propagation maps use different colors, the algorithms are largely capturing similar patterns, as the tracts tend to end up in similar groups across the maps. According to the silhouette score, the kmeans solution fits the best (.284).\n\nks_best, ks_table = gaz.find_region_k(\n    gdf=atl,\n    method=\"ward_spatial\",\n    columns=columns,\n    min_k=2,\n    max_k=50,\n    return_table=True,\n    weights_kwargs=dict(use_index=True),\n)\n\n\n\n\n\nks_best\n\n\n\n\n\n\n\n\nsilhouette_score\ncalinski_harabasz_score\npath_silhouette\nboundary_silhouette\ndavies_bouldin_score\n\n\ntime_period\n\n\n\n\n\n\n\n\n\n2021.0\n2.0\n2.0\n2.0\n2.0\n2.0\n\n\n\n\n\n\n\n\nks_table\n\n\n\n\n\n\n\n\nsilhouette_score\ncalinski_harabasz_score\ndavies_bouldin_score\npath_silhouette\nboundary_silhouette\ntime_period\n\n\nk\n\n\n\n\n\n\n\n\n\n\n2.0\n0.434042\n1022.153887\n0.919060\n0.240690\n0.228754\n2021.0\n\n\n3.0\n0.019951\n551.161697\n1.759504\n0.046024\n0.144925\n2021.0\n\n\n4.0\n-0.019597\n368.492751\n3.534141\n-0.029050\n0.129196\n2021.0\n\n\n5.0\n-0.043651\n384.596847\n3.111063\n-0.038028\n0.150757\n2021.0\n\n\n6.0\n-0.064825\n309.203466\n4.034292\n-0.009382\n0.134346\n2021.0\n\n\n7.0\n-0.115964\n263.065537\n4.390554\n-0.001343\n0.129806\n2021.0\n\n\n8.0\n-0.130498\n245.804728\n4.560684\n0.010257\n0.133215\n2021.0\n\n\n9.0\n-0.186255\n215.409648\n4.966430\n-0.049966\n0.128536\n2021.0\n\n\n10.0\n-0.181418\n202.209407\n5.262141\n-0.058031\n0.138581\n2021.0\n\n\n11.0\n-0.181117\n183.542932\n6.455455\n-0.069527\n0.137101\n2021.0\n\n\n12.0\n-0.221784\n166.741885\n9.303724\n-0.117650\n0.130112\n2021.0\n\n\n13.0\n-0.251297\n156.879027\n8.617757\n-0.160299\n0.130387\n2021.0\n\n\n14.0\n-0.267361\n145.949990\n8.355656\n-0.151551\n0.121871\n2021.0\n\n\n15.0\n-0.269082\n159.829301\n7.838451\n-0.151715\n0.138553\n2021.0\n\n\n16.0\n-0.268016\n179.946439\n7.635913\n-0.140382\n0.156045\n2021.0\n\n\n17.0\n-0.283965\n173.074427\n7.804872\n-0.151713\n0.156887\n2021.0\n\n\n18.0\n-0.296362\n163.567578\n7.575793\n-0.161408\n0.152017\n2021.0\n\n\n19.0\n-0.328097\n155.996562\n7.764501\n-0.180268\n0.157039\n2021.0\n\n\n20.0\n-0.326098\n151.998976\n7.565655\n-0.175524\n0.157896\n2021.0\n\n\n21.0\n-0.320600\n152.293209\n9.766708\n-0.164365\n0.160368\n2021.0\n\n\n22.0\n-0.320377\n146.273670\n9.562961\n-0.153741\n0.159841\n2021.0\n\n\n23.0\n-0.319841\n145.020083\n9.826365\n-0.142174\n0.166613\n2021.0\n\n\n24.0\n-0.319699\n139.014171\n11.263353\n-0.139394\n0.162061\n2021.0\n\n\n25.0\n-0.316411\n138.210103\n9.597011\n-0.141349\n0.175121\n2021.0\n\n\n26.0\n-0.316992\n140.074212\n9.588288\n-0.139715\n0.177051\n2021.0\n\n\n27.0\n-0.316857\n134.746578\n10.285678\n-0.148829\n0.174480\n2021.0\n\n\n28.0\n-0.316798\n129.802607\n10.821965\n-0.097511\n0.173355\n2021.0\n\n\n29.0\n-0.315606\n126.908030\n11.247913\n-0.104650\n0.174590\n2021.0\n\n\n30.0\n-0.318442\n122.725128\n11.291424\n-0.116968\n0.171425\n2021.0\n\n\n31.0\n-0.318772\n118.929814\n11.293531\n-0.120727\n0.168074\n2021.0\n\n\n32.0\n-0.338832\n115.047005\n12.352933\n-0.135030\n0.164883\n2021.0\n\n\n33.0\n-0.338542\n112.985826\n11.957396\n-0.129456\n0.162017\n2021.0\n\n\n34.0\n-0.359114\n109.778961\n16.666269\n-0.130238\n0.161501\n2021.0\n\n\n35.0\n-0.356039\n106.512340\n18.389338\n-0.073573\n0.160688\n2021.0\n\n\n36.0\n-0.354490\n103.932576\n15.938880\n-0.076887\n0.161395\n2021.0\n\n\n37.0\n-0.352066\n102.428061\n15.182044\n-0.072158\n0.160066\n2021.0\n\n\n38.0\n-0.345542\n104.198992\n14.973328\n-0.047461\n0.163435\n2021.0\n\n\n39.0\n-0.345621\n101.438472\n16.821767\n-0.039939\n0.158323\n2021.0\n\n\n40.0\n-0.356106\n101.833020\n17.464491\n-0.041503\n0.161624\n2021.0\n\n\n41.0\n-0.355662\n99.346309\n18.949288\n-0.043187\n0.157395\n2021.0\n\n\n42.0\n-0.355442\n96.898996\n18.789024\n-0.027600\n0.156367\n2021.0\n\n\n43.0\n-0.365141\n95.597666\n19.138150\n-0.025779\n0.161671\n2021.0\n\n\n44.0\n-0.362219\n94.346053\n18.752235\n-0.027080\n0.167585\n2021.0\n\n\n45.0\n-0.359985\n95.326860\n18.320573\n-0.025545\n0.168185\n2021.0\n\n\n46.0\n-0.360445\n94.441865\n13.887016\n-0.021721\n0.166699\n2021.0\n\n\n47.0\n-0.364280\n92.839890\n13.697263\n-0.025290\n0.164530\n2021.0\n\n\n48.0\n-0.362108\n91.905597\n14.320967\n-0.020906\n0.165589\n2021.0\n\n\n49.0\n-0.368300\n90.714049\n14.423774\n-0.024425\n0.163852\n2021.0\n\n\n50.0\n-0.382137\n89.144165\n13.673787\n-0.030526\n0.164703\n2021.0\n\n\n\n\n\n\n\n\nks_table.columns\n\nIndex(['silhouette_score', 'calinski_harabasz_score', 'davies_bouldin_score',\n       'path_silhouette', 'boundary_silhouette', 'time_period'],\n      dtype='object')\n\n\n\nf, ax = plt.subplots(2, 3, figsize=(15, 10))\nax = ax.flatten()\n\nfor i, metric in enumerate(ks_table.columns.values):\n    ks_table[metric].plot(ax=ax[i])\n    ax[i].set_title(metric)\n\n\n\n\nThe path silhouette is highest at about 8 or 48, whereas the boundary silhouette has a peak at 27. Each of these could be justified in a certain context, depending on the research question.\nIn addition to the set of compositional attributes, a crucial input to regionalization algorithms is the spatial weights parameter (W), which defines the “geographic similarity” between units. Generally, the goal of regionalization algorithms is to define a distinct, contiguous [set of] region(s), which usually means using a contiguity-based W object (and as such, the default W is a Rook weight). But it is also possible to relax the contiguity enforcement using something like a distance-band weight, which would group nearby observations even if they are not necessarily touching each other.\n\nfrom libpysal.weights import DistanceBand\n\natl_distance_band = gaz.regionalize(\n    gdf=atl,\n    columns=columns,\n    method=\"ward_spatial\",\n    n_clusters=10,\n    spatial_weights=DistanceBand,\n    weights_kwargs=dict(threshold=2000),\n)\n\n\natl_distance_band[['ward_spatial', 'geometry']].explore('ward_spatial', categorical=True, tiles='CartoDB Positron')\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "dynamics.html#examining-data",
    "href": "dynamics.html#examining-data",
    "title": "6  Neighborhood Dynamics",
    "section": "6.1 Examining Data",
    "text": "6.1 Examining Data\n\nstore = DataStore()\n\nThe DataStore class provides access to hundreds of neighbrohood indicators for the U.S. collected from federal agencies. We store these datasets in the cloud and stream them on demand. But if you plan on doing repeated analyses you can store the data locally (which we’ve already done on the JupyterHub)\n\nchicago = get_acs(store, county_fips='17031', level='tract', years=list(range(2013, 2017)))  # without specifying a subset of years, we get everything\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/io/constructors.py:188: UserWarning: `constant_dollars` is True, but no `currency_year` was specified. Resorting to max value of 2016\n  warn(\n\n\n\nchicago.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nRangeIndex: 5276 entries, 0 to 5275\nColumns: 161 entries, geoid to p_vietnamese_persons\ndtypes: float64(158), geometry(1), int64(1), object(1)\nmemory usage: 6.5+ MB\n\n\n\nchicago.head()\n\n\n\n\n\n\n\n\ngeoid\nn_mexican_pop\nn_cuban_pop\nn_puerto_rican_pop\nn_russian_pop\nn_italian_pop\nn_german_pop\nn_irish_pop\nn_scandaniavian_pop\nn_foreign_born_pop\n...\nn_chinese_persons\nn_filipino_persons\nn_japanese_persons\nn_korean_persons\nn_vietnamese_persons\np_chinese_persons\np_filipino_persons\np_japanese_persons\np_korean_persons\np_vietnamese_persons\n\n\n\n\n0\n17031010100\n235.0\n0.0\n84.0\n0.0\n31.0\n78.0\n21.0\n0.0\n996.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n17031010201\n1745.0\n0.0\n38.0\n60.0\n81.0\n31.0\n63.0\n0.0\n2530.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n17031010202\n480.0\n16.0\n6.0\n8.0\n34.0\n104.0\n55.0\n0.0\n676.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\n17031010300\n636.0\n54.0\n16.0\n152.0\n38.0\n138.0\n190.0\n0.0\n1951.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\n17031010400\n269.0\n79.0\n67.0\n20.0\n111.0\n206.0\n177.0\n0.0\n822.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 161 columns\n\n\n\nThere are also convenient plotting methods for looking at change over time. A useful feature here is that the choropleth bins are the same for each time period, making it easy to see change over time\n\nimport matplotlib.pyplot as plt\nplot_timeseries(chicago, \"median_home_value\", scheme='quantiles', k=7, nrows=2, ncols=2, cmap='YlOrBr', figsize=(12,16), legend=False)\nplt.tight_layout()\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/visualize/mapping.py:170: UserWarning: `proplot` is not installed.  Falling back to matplotlib\n  warn(\"`proplot` is not installed.  Falling back to matplotlib\")\n\n\n\n\n\nStill it can be difficult to see minute changes across the various maps. The animate_timeseries function can make it easier to see what’s happening, like the steady income decline in Midlothian near the southern edge of the region\n\nanimate_timeseries(chicago, 'median_home_value', scheme='quantiles', k=7, cmap='YlOrBr', filename='chicago_income_change.gif', fps=1.5)\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 1000x1000 with 0 Axes&gt;\n\n\n\nfrom IPython.display import Image\n\n\nImage(\"chicago_income_change.gif\", width=800)\n\n&lt;IPython.core.display.Image object&gt;\n\n\nNote here that we’re comparing overlapping samples from the ACS 5-year survey, which the Census Bureau recommends against. Here it just makes a good example :)"
  },
  {
    "objectID": "dynamics.html#modeling-neighborhood-types",
    "href": "dynamics.html#modeling-neighborhood-types",
    "title": "6  Neighborhood Dynamics",
    "section": "6.2 Modeling Neighborhood Types",
    "text": "6.2 Modeling Neighborhood Types\nWith geosnap, it’s possible to look at temporal geodemographics without writing much code. Under the hood, the package provides tools for scaling each dataset within its own time period, adjusting currency values for inflation, and ensuring that times, variables, and geometries stay aligned properly. Together those tools make it easy to explore how different portions of the region transition into different neighborhood types over time, and if desired, model the evolution of neighborhood change as a spatial Markov process.\nAny variables could be used to examine neighborhood transitions, but we’ll return to the simple set of sociodemographic veriables used before to understand if/how patterns of racial and socioeconomic segregation and neighborhood partitioning unfold over time\n\ncolumns = ['median_household_income', 'median_home_value', 'p_asian_persons', 'p_hispanic_persons', 'p_nonhisp_black_persons', 'p_nonhisp_white_persons']\n\n\nchicago_ward = cluster(gdf=chicago, columns=columns, method='ward', n_clusters=5)\n\nThe simplest version of the function returns the geodataframe with new cluster labels appended\n\nchicago_ward.head()\n\n\n\n\n\n\n\n\nyear\ngeoid\nn_mexican_pop\nn_cuban_pop\nn_puerto_rican_pop\nn_russian_pop\nn_italian_pop\nn_german_pop\nn_irish_pop\nn_scandaniavian_pop\n...\nn_filipino_persons\nn_japanese_persons\nn_korean_persons\nn_vietnamese_persons\np_chinese_persons\np_filipino_persons\np_japanese_persons\np_korean_persons\np_vietnamese_persons\nward\n\n\n\n\n0\n2013\n17031010100\n235.0\n0.0\n84.0\n0.0\n31.0\n78.0\n21.0\n0.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2\n\n\n1\n2013\n17031010201\n1745.0\n0.0\n38.0\n60.0\n81.0\n31.0\n63.0\n0.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2\n\n\n2\n2013\n17031010202\n480.0\n16.0\n6.0\n8.0\n34.0\n104.0\n55.0\n0.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2\n\n\n3\n2013\n17031010300\n636.0\n54.0\n16.0\n152.0\n38.0\n138.0\n190.0\n0.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0\n\n\n4\n2013\n17031010400\n269.0\n79.0\n67.0\n20.0\n111.0\n206.0\n177.0\n0.0\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0\n\n\n\n\n5 rows × 162 columns\n\n\n\n\nplot_timeseries(chicago_ward, 'ward', categorical=True, nrows=2, ncols=2, figsize=(12,16))\nplt.tight_layout()\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/visualize/mapping.py:170: UserWarning: `proplot` is not installed.  Falling back to matplotlib\n  warn(\"`proplot` is not installed.  Falling back to matplotlib\")\n\n\n\n\n\n\nanimate_timeseries(chicago_ward, 'ward', categorical=True, filename='chicago_type_change.gif', fps=1.5)\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 1000x1000 with 0 Axes&gt;\n\n\nThe vast majority of tracts are assigned to the same geodemographic type in each time period, but some transition into different types over time. The ones that do transition tend to be those on the edges of large contiguous groups (i.e. change tends to happen along the periphery and move inward, implying a certain kind of spatial dynamic)\n\nImage('chicago_type_change.gif', width=800)\n\n&lt;IPython.core.display.Image object&gt;\n\n\nIf we add the argument return_model=True, then the function returns the same geodataframe as before, as well as a ModelResults class that holds additional diagnostic measures, as well as plotting and simulation methods\n\nchicago_ward, chi_model = cluster(chicago, columns=columns, method='ward', n_clusters=6, return_model=True)\n\n\ntype(chi_model)\n\ngeosnap.analyze._model_results.ModelResults\n\n\nFor example, the silhouette_scores attribute makes computing a silhouette coefficient for the cluster model a one-liner:\n\nchi_model.silhouette_scores\n\n\n\n\n\n\n\n\nsilhouette_score\ngeoid\nyear\ngeometry\n\n\n\n\n0\n0.136093\n17031010100\n2013\nMULTIPOLYGON (((-87.67720 42.02294, -87.67628 ...\n\n\n1\n0.099845\n17031010201\n2013\nMULTIPOLYGON (((-87.68465 42.01948, -87.68432 ...\n\n\n2\n-0.178627\n17031010202\n2013\nMULTIPOLYGON (((-87.67683 42.01941, -87.67674 ...\n\n\n3\n0.188316\n17031010300\n2013\nMULTIPOLYGON (((-87.67133 42.01937, -87.67121 ...\n\n\n4\n-0.141755\n17031010400\n2013\nMULTIPOLYGON (((-87.66345 42.01283, -87.66321 ...\n\n\n...\n...\n...\n...\n...\n\n\n5268\n0.522373\n17031843500\n2016\nMULTIPOLYGON (((-87.70504 41.84452, -87.70479 ...\n\n\n5269\n0.603410\n17031843600\n2016\nMULTIPOLYGON (((-87.61150 41.81128, -87.61125 ...\n\n\n5270\n0.019169\n17031843700\n2016\nMULTIPOLYGON (((-87.69683 41.94967, -87.69681 ...\n\n\n5271\n0.102991\n17031843800\n2016\nMULTIPOLYGON (((-87.64554 41.80886, -87.64542 ...\n\n\n5272\n0.680673\n17031843900\n2016\nMULTIPOLYGON (((-87.59295 41.77508, -87.59278 ...\n\n\n\n\n5224 rows × 4 columns\n\n\n\nEach observation is given its own silhouette score to identify potential spatial outliers, or the measures can be summarized to provide an aggregate statistic\n\nchi_model.silhouette_scores.silhouette_score.mean()\n\n0.35971262107670565\n\n\nSince the data are indexed by time, we can also examine whether certain time periods have a poorer fit versus others:\n\nchi_model.silhouette_scores.groupby('year').silhouette_score.mean()\n\nyear\n2013    0.362116\n2014    0.361529\n2015    0.359077\n2016    0.356111\nName: silhouette_score, dtype: float64"
  },
  {
    "objectID": "dynamics.html#analyzing-neighborhood-change",
    "href": "dynamics.html#analyzing-neighborhood-change",
    "title": "6  Neighborhood Dynamics",
    "section": "6.3 Analyzing Neighborhood Change",
    "text": "6.3 Analyzing Neighborhood Change\nWith the cluster model in hand, each census tract is represented as a series of neighborhood types over time (i.e. what we plotted above). To understand which neighborhoods have experienced the most change, the ModelResults class implements a method called “LINCS”, the Local Indicator of Neighborhood Change. The lincs attribute measures how often a given spatial unit shares its cluster assignment with the other units over time.\nIf a “neighborhood” is grouped with many different neighborhoods over time (rather than joining a single group with the same members repeatedly), then it shows more variation and thus a higher LINC score\n\nchi_lincs = chi_model.lincs\n\n\nchi_lincs\n\n\n\n\n\n\n\n\ngeoid\ngeometry\n2013\n2014\n2015\n2016\nlinc\n\n\n\n\n0\n17031010100\nMULTIPOLYGON (((-87.67720 42.02294, -87.67628 ...\n0.0\n0.0\n0.0\n0.0\n0.017857\n\n\n1\n17031010201\nMULTIPOLYGON (((-87.68465 42.01948, -87.68432 ...\n0.0\n0.0\n0.0\n0.0\n0.017857\n\n\n2\n17031010202\nMULTIPOLYGON (((-87.67683 42.01941, -87.67674 ...\n0.0\n0.0\n0.0\n0.0\n0.017857\n\n\n3\n17031010300\nMULTIPOLYGON (((-87.67133 42.01937, -87.67121 ...\n2.0\n2.0\n2.0\n2.0\n0.303371\n\n\n4\n17031010400\nMULTIPOLYGON (((-87.66345 42.01283, -87.66321 ...\n2.0\n2.0\n2.0\n2.0\n0.303371\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1304\n17031843500\nMULTIPOLYGON (((-87.70504 41.84452, -87.70479 ...\n0.0\n0.0\n0.0\n0.0\n0.017857\n\n\n1305\n17031843600\nMULTIPOLYGON (((-87.61150 41.81128, -87.61125 ...\n0.0\n0.0\n0.0\n0.0\n0.017857\n\n\n1306\n17031843700\nMULTIPOLYGON (((-87.69683 41.94967, -87.69681 ...\n4.0\n4.0\n4.0\n3.0\n0.994307\n\n\n1307\n17031843800\nMULTIPOLYGON (((-87.64554 41.80886, -87.64542 ...\n0.0\n0.0\n0.0\n0.0\n0.017857\n\n\n1308\n17031843900\nMULTIPOLYGON (((-87.59295 41.77508, -87.59278 ...\n0.0\n0.0\n0.0\n0.0\n0.017857\n\n\n\n\n1309 rows × 7 columns\n\n\n\n\nchi_lincs.plot('linc',legend=True, cmap='plasma')\n\n&lt;Axes: &gt;\n\n\n\n\n\nYellow places have changed the most in our cluster model, and blue places have remained the most stagnant. We can use the LISA statistics from esda to locate hotspots of change or stagnation\n\nchi_lincs.linc.plot(kind='density')\n\n&lt;Axes: ylabel='Density'&gt;\n\n\n\n\n\n\nfrom esda import Moran_Local\n\n\nfrom libpysal.weights import Queen\n\n\nw = Queen.from_dataframe(chi_model.lincs)\n\n/var/folders/79/cknfb1sx2pv16rztkpg6wzlw0000gn/T/ipykernel_75148/3977480944.py:1: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n  w = Queen.from_dataframe(chi_model.lincs)\n\n\n\nlinc_lisa = Moran_Local(chi_lincs.linc, w)\n\nRecall that the LISA statistic measures the association between a focal observation and its neighbors. When we have spatial units (i.e. tracts) with a high LINC score, and their neighboring tracts also have high LINC scores, then we’ve found a local pocket of neighborhood change.\n\nlinc_lisa.Is\n\narray([ 0.19094133, -0.38635302, -0.13315014, ...,  2.09900215,\n        0.3517673 ,  0.49985707])\n\n\n\nchi_lincs.assign(i=linc_lisa.Is).plot('i', legend=True)\n\n&lt;Axes: &gt;\n\n\n\n\n\n\nfrom splot.esda import plot_local_autocorrelation, lisa_cluster\n\n\nplot_local_autocorrelation(linc_lisa, chi_lincs.to_crs(3857), 'linc')\n\n(&lt;Figure size 1500x400 with 3 Axes&gt;,\n array([&lt;Axes: title={'center': 'Moran Local Scatterplot'}, xlabel='Attribute', ylabel='Spatial Lag'&gt;,\n        &lt;Axes: &gt;, &lt;Axes: &gt;], dtype=object))\n\n\n\n\n\n\nimport contextily as ctx\n\n\nfig, ax = lisa_cluster(linc_lisa, chi_lincs.to_crs(3857), alpha=0.6, figsize=(8,10))\nctx.add_basemap(ax=ax, source=ctx.providers.CartoDB.Positron, zoom=11)\nfig.tight_layout()\n\n\n\n\nRed areas of high-high clusters of LINC scores are places undergoing change, whereas blue places (low LINC scores surrounded by low scores) are those that have changed very little over time. Orange places are particularly interesting, as they represent local pockets of change surrounded by larger pockets of stagnation.\nSubstantively, this example shows that Chicago’s famously segregated South Side and West Side form large regions of the city that demonstrate little demographic/socioeconomic change, particularly in neighborhoods like Rosewood and West Garfield. By contrast, places like Brideport and Portage Park have witnessed substantial change over the last decade according to this model"
  },
  {
    "objectID": "dynamics.html#modeling-neighborhood-transitions",
    "href": "dynamics.html#modeling-neighborhood-transitions",
    "title": "6  Neighborhood Dynamics",
    "section": "6.4 Modeling Neighborhood Transitions",
    "text": "6.4 Modeling Neighborhood Transitions\nWe can also use the sequence of labels to create a spatial Markov transition model. These models examine how often one neighborhood type transitions into another type–then how these transition rates change under different conditions of spatial context\n\nfrom geosnap.visualize import plot_transition_matrix\n\n\nplot_transition_matrix(chicago_ward, cluster_col='ward')\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/visualize/transitions.py:82: UserWarning: Creating a transition model implicitly is deprecated and will be removed in future versions. please pass a giddy.Spatial_Markov instance using `giddy` or `geosnap.analyze.transition`\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:123: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n  w = Ws[w_type].from_dataframe(gpd.GeoDataFrame(gdf_wide), **w_options)\n\n\narray([&lt;Axes: title={'center': 'Global'}&gt;,\n       &lt;Axes: title={'center': 'Modal Neighbor - 0'}&gt;,\n       &lt;Axes: title={'center': 'Modal Neighbor - 1'}&gt;,\n       &lt;Axes: title={'center': 'Modal Neighbor - 2'}&gt;,\n       &lt;Axes: title={'center': 'Modal Neighbor - 3'}&gt;,\n       &lt;Axes: title={'center': 'Modal Neighbor - 4'}&gt;,\n       &lt;Axes: title={'center': 'Modal Neighbor - 5'}&gt;, &lt;Axes: &gt;, &lt;Axes: &gt;],\n      dtype=object)\n\n\n\n\n\nAnd we can use those transition rates to make predictions about future conditions\n\nfuture = chi_model.predict_markov_labels(time_steps=10, increment=1)\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/_model_results.py:777: UserWarning: No base_year provided. Using the last period for which labels are known:  2016 \n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:123: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n  w = Ws[w_type].from_dataframe(gpd.GeoDataFrame(gdf_wide), **w_options)\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:330: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n  w = Ws[w_type].from_dataframe(gdf, **w_options)\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031811401\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031220602\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031220602\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031811401\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031814700\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031600600\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031811401\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031600600\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031811401\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031600600\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031811401\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031600600\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031811401\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031600600\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031811401\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031839800\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031600600\n  warn(\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/dynamics.py:392: UserWarning: Falling back to aspatial transition rule for unit 17031811401\n  warn(\n\n\n\nanimate_timeseries(future, 'predicted', categorical=True, filename='chicago_predictions.gif', fps=1.5)\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 1000x1000 with 0 Axes&gt;\n\n\n\nImage('chicago_predictions.gif', width=800)\n\n&lt;IPython.core.display.Image object&gt;\n\n\nFrom a social equity perspective, these predictions can help inform investments in place that are likely to provide the greatest return, such as providing place-based affordable houising in high-opportunity (but low likelihood of change) or by providing displacement protections in places that show large potential for change"
  },
  {
    "objectID": "segregation_dynamics.html#racial-segregation-over-time",
    "href": "segregation_dynamics.html#racial-segregation-over-time",
    "title": "7  Spatiotemporal Segregation Dynamics",
    "section": "7.1 Racial Segregation over Time",
    "text": "7.1 Racial Segregation over Time\n\ngroups = ['n_nonhisp_white_persons', 'n_nonhisp_black_persons', 'n_hispanic_persons', 'n_asian_persons']\n\n\nplot_timeseries(dc, 'p_nonhisp_white_persons', nrows=1, ncols=3, figsize=(18,10), cmap='Blues', alpha=0.8)\nplt.tight_layout()\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/visualize/mapping.py:170: UserWarning: `proplot` is not installed.  Falling back to matplotlib\n  warn(\"`proplot` is not installed.  Falling back to matplotlib\")\n\n\n\n\n\n\n7.1.1 Temporal Dynamics\n\n7.1.1.1 Multi-Group Indices\n\nmulti_by_time = segdyn.multigroup_tempdyn(dc, groups)\n\n\nmulti_by_time\n\n\n\n\n\n\n\nyear\n2012\n2016\n2021\n\n\nName\n\n\n\n\n\n\n\nGlobalDistortion\n191.2887\n179.0859\n195.9176\n\n\nMultiDissim\n0.5263\n0.5138\n0.5151\n\n\nMultiDivergence\n0.3845\n0.3727\n0.3900\n\n\nMultiDiversity\n1.1958\n1.2200\n1.2499\n\n\nMultiGini\n0.6952\n0.6788\n0.6816\n\n\nMultiInfoTheory\n0.3215\n0.3055\n0.3120\n\n\nMultiNormExposure\n0.3315\n0.3169\n0.3150\n\n\nMultiRelativeDiversity\n0.3196\n0.3061\n0.3066\n\n\nMultiSquaredCoefVar\n0.2640\n0.2579\n0.2700\n\n\nSimpsonsConcentration\n0.3503\n0.3375\n0.3212\n\n\nSimpsonsInteraction\n0.6497\n0.6625\n0.6788\n\n\n\n\n\n\n\n\nmulti_by_time.T.plot()\n\n&lt;Axes: xlabel='year'&gt;\n\n\n\n\n\n\n# removing the GlobalDistortion coef lets us see what's happening with the rest of the indices\nmulti_by_time.iloc[1:].T.plot()\n\n&lt;Axes: xlabel='year'&gt;\n\n\n\n\n\nMost indices are changing little over time, but most have followed the same trend with a mild drop in 2016 prior to a slight increase in the latest available data\n\nfig, axs = plt.subplots(1,2, figsize=(10,4))\n\nmulti_by_time.loc['MultiDissim'].plot(ax=axs[0])\nmulti_by_time.loc['MultiDissim'].plot(kind='bar', ax=axs[1])\n\nfig.suptitle(\"Multigroup Dissimilarity\")\n\nText(0.5, 0.98, 'Multigroup Dissimilarity')\n\n\n\n\n\nOne that isn’t, is SimpsonsConcentration, which is increasing over time. Another index that bucks the trend is SimpsonsInteraction, which is decreasing over time (corresponding with an increse in segregation). The divergence between indices tells us that segregation may be changing in different ways across its different dimensions.\n\nfig, axs = plt.subplots(1,2, figsize=(10,4))\n\nmulti_by_time.loc['SimpsonsConcentration'].plot(ax=axs[0])\nmulti_by_time.loc['SimpsonsConcentration'].plot(kind='bar', ax=axs[1])\n\nfig.suptitle(\"Simpson's Concentration\")\n\nText(0.5, 0.98, \"Simpson's Concentration\")\n\n\n\n\n\n\n\n7.1.1.2 Single-Group Indices\n\nfrom geosnap.analyze.segdyn import singlegroup_tempdyn\n\n\nsinglegroup_tempdyn?\n\n\nSignature:\nsinglegroup_tempdyn(\n    gdf,\n    group_pop_var=None,\n    total_pop_var=None,\n    time_index='year',\n    n_jobs=-1,\n    backend='loky',\n    **index_kwargs,\n)\nDocstring:\nBatch compute singlegroup segregation indices for each time period in parallel.\nParameters\n----------\ngdf : geopandas.GeoDataFrame\n    geodataframe formatted as a long-form timeseries\ngroup_pop_var : str\n    name of column on gdf containing population counts for the group of interest\ntotal_pop_var : str\n    name of column on gdf containing total population counts for the unit\ntime_index : str\n    column on the dataframe that denotes unique time periods, by default \"year\"\nn_jobs : int, optional\n    number of cores to use for computation. If -1, all available cores will be\n    used, by default -1\nbackend : str, optional\n    computation backend passed to joblib. One of {'multiprocessing', 'loky',\n    'threading'}, by default \"loky\"\nReturns\n-------\ngeopandas.GeoDataFrame\n    dataframe with unique segregation indices as rows and estimates for each\n    time period as columns\nFile:      ~/Dropbox/projects/geosnap/geosnap/analyze/segdyn.py\nType:      function\n\n\n\n\ndc['blackwhite'] = dc.n_nonhisp_black_persons + dc.n_nonhisp_white_persons\n\n\nsegs_single = segdyn.singlegroup_tempdyn(dc, group_pop_var='n_nonhisp_black_persons', total_pop_var='blackwhite' )\n\nGini:  52%|█████▏    | 14/27 [00:19&lt;00:20,  1.55s/it]                    OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\nOMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\nModifiedGini:  70%|███████   | 19/27 [00:22&lt;00:06,  1.25it/s]            OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\nSpatialProximity: 100%|██████████| 27/27 [00:52&lt;00:00,  1.95s/it]      \nSpatialProximity: 100%|██████████| 27/27 [00:53&lt;00:00,  1.97s/it]\nSpatialProximity: 100%|██████████| 27/27 [01:02&lt;00:00,  2.30s/it]\n\n\n\nsegs_single\n\n\n\n\n\n\n\nyear\n2012\n2016\n2021\n\n\nName\n\n\n\n\n\n\n\nAbsoluteCentralization\n0.6945\n0.6938\n0.6804\n\n\nAbsoluteClustering\n0.3263\n0.3326\n0.3613\n\n\nAbsoluteConcentration\n0.8278\n0.8284\n0.8270\n\n\nAtkinson\n0.6294\n0.6069\n0.6106\n\n\nBiasCorrectedDissim\n0.6523\n0.6443\n0.6463\n\n\nBoundarySpatialDissim\n0.5239\n0.5191\n0.4999\n\n\nConProf\n0.6069\n0.6020\n0.6068\n\n\nCorrelationR\n0.5192\n0.5065\n0.5097\n\n\nDelta\n0.7937\n0.7921\n0.7920\n\n\nDensityCorrectedDissim\n0.5064\n0.4942\n0.5153\n\n\nDissim\n0.6526\n0.6446\n0.6466\n\n\nDistanceDecayInteraction\n0.4776\n0.4797\n0.4707\n\n\nDistanceDecayIsolation\n0.5349\n0.5366\n0.5523\n\n\nEntropy\n0.4665\n0.4511\n0.4538\n\n\nGini\n0.8248\n0.8137\n0.8164\n\n\nInteraction\n0.3174\n0.3227\n0.3144\n\n\nIsolation\n0.6826\n0.6773\n0.6856\n\n\nMinMax\n0.7898\n0.7839\n0.7854\n\n\nModifiedDissim\n0.6442\n0.6364\n0.6377\n\n\nModifiedGini\n0.8186\n0.8071\n0.8099\n\n\nPARDissim\n0.6379\n0.6303\n0.6327\n\n\nRelativeCentralization\n-0.0193\n-0.0258\n-0.0424\n\n\nRelativeClustering\n0.7093\n0.7241\n0.7556\n\n\nRelativeConcentration\n0.6029\n0.6142\n0.6299\n\n\nSpatialDissim\n0.5171\n0.5121\n0.4943\n\n\nSpatialProxProf\n0.5772\n0.5896\n0.6116\n\n\nSpatialProximity\n1.2668\n1.2650\n1.2801\n\n\n\n\n\n\n\n\nsegs_single.T.hvplot(height=600)\n\n\n\n\n\n  \n\n\n\n\nhttps://www.jstor.org/stable/2579183\n\nIFrame('https://www.jstor.org/stable/2579183', height=600, width=800)\n\n\n\n        \n        \n\n\n\n(segs_single.T[['Gini', 'Entropy', 'Dissim', 'Atkinson']].hvplot(title='Evenness Dimension', width=380, height=400).opts(legend_position='bottom', show_grid=True) +\nsegs_single.T[['AbsoluteConcentration', 'RelativeConcentration' , 'Delta']].hvplot(title='Concentration Dimension', width=380, height=400).opts(legend_position='bottom', show_grid=True) +\nsegs_single.T[['AbsoluteClustering', 'Isolation', 'CorrelationR', 'Interaction', 'SpatialProxProf']].hvplot(title='Exposure/Clustering Dimension', width=380, height=400).opts(legend_position='bottom', show_grid=True))\n\n\n\n\n\n  \n\n\n\n\n\nsegs_single.T[['AbsoluteClustering', 'Isolation', 'SpatialProxProf', 'Interaction']].pct_change(periods=5) # we should only compare non-overlapping intervals\n\n\n\n\n\n\n\nName\nAbsoluteClustering\nIsolation\nSpatialProxProf\nInteraction\n\n\nyear\n\n\n\n\n\n\n\n\n2012\nNaN\nNaN\nNaN\nNaN\n\n\n2016\nNaN\nNaN\nNaN\nNaN\n\n\n2021\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nBetween the sampling periods 2008-2012 and 2013-2017: - the isolation index increased by 5.2% - the absolute clustering index increased by 12.4%.\n- the spatial proximity profile increased by 17.6%\nBetween the sampling periods 2009-2013 and 2014-2018: - the isolation index increased by 7.9% - the absolute clustering index increased by 18.2% - the spatial proximity profile increased by 21.9%"
  },
  {
    "objectID": "segregation_dynamics.html#space-time-dynamics",
    "href": "segregation_dynamics.html#space-time-dynamics",
    "title": "7  Spatiotemporal Segregation Dynamics",
    "section": "7.2 Space-Time Dynamics",
    "text": "7.2 Space-Time Dynamics\n\nfrom segregation.singlegroup import Entropy\n\n\nd = segdyn.spacetime_dyn(dc, singlegroup.Entropy, group_pop_var='n_nonhisp_black_persons', total_pop_var='blackwhite', distances=list(range(500,5500,500)))\n\n\nd.plot(cmap='Reds')\n\n&lt;Axes: xlabel='distance'&gt;\n\n\n\n\n\nEntropy is falling the fastest at large scales (the gap is wider on the right-hand side of the graph than the left-hand side)\n\niso = segdyn.spacetime_dyn(dc, singlegroup.Isolation, group_pop_var='n_nonhisp_black_persons', total_pop_var='blackwhite', distances=list(range(500,5500,500)))\n\n\niso.plot(cmap='Reds')\n\n&lt;Axes: xlabel='distance'&gt;\n\n\n\n\n\nIsolation is growing the fastest at large scales (the gap is wider with larger distances on the right). Isolation is actually growing at the smallest scale\n\nfrom geosnap.visualize import animate_timeseries\n\n\nanimate_timeseries(dc, 'p_nonhisp_black_persons', filename='dc_black_pop_change.gif', fps=1.5)\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 2000x2000 with 0 Axes&gt;\n\n\n&lt;Figure size 1000x1000 with 0 Axes&gt;\n\n\n\nfrom IPython.display import Image\n\n\nImage('dc_black_pop_change.gif',width=800)\n\n&lt;IPython.core.display.Image object&gt;"
  },
  {
    "objectID": "segregation_dynamics.html#using-geosnap-as-a-dashboard-engine",
    "href": "segregation_dynamics.html#using-geosnap-as-a-dashboard-engine",
    "title": "7  Spatiotemporal Segregation Dynamics",
    "section": "7.3 Using geosnap as a Dashboard Engine",
    "text": "7.3 Using geosnap as a Dashboard Engine\nThe Python dashboarding ecosystem is evolving quickly, so we won’t opine on which platform or toolset is best. But if you have a personal favorite, geosnap is performant to power an urban analytics dashboard on-the-fly. The example below wraps a simple streamlit interface around the workflow above that lets us explore every metro region quickly\nexample: https://github.com/knaaptime/incseg_app"
  },
  {
    "objectID": "segregation_dynamics.html#demo",
    "href": "segregation_dynamics.html#demo",
    "title": "7  Spatiotemporal Segregation Dynamics",
    "section": "7.4 Demo",
    "text": "7.4 Demo"
  },
  {
    "objectID": "isochrone_example.html#pedestrian-travel-isochrones-visualizing-the-20-minute-neighborhood",
    "href": "isochrone_example.html#pedestrian-travel-isochrones-visualizing-the-20-minute-neighborhood",
    "title": "8  Egohoods and Isochrones",
    "section": "8.1 Pedestrian Travel Isochrones: Visualizing the 20-Minute Neighborhood",
    "text": "8.1 Pedestrian Travel Isochrones: Visualizing the 20-Minute Neighborhood\n\n%load_ext watermark\n%watermark -a 'eli knaap' -v -d -u -p geopandas,geosnap\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/_data.py:66: UserWarning: The geosnap data storage class is provided for convenience only. The geosnap developers make no promises regarding data quality, consistency, or availability, nor are they responsible for any use/misuse of the data. The end-user is responsible for any and all analyses or applications created with the package.\n  warn(\n\n\nAuthor: eli knaap\n\nLast updated: 2022-06-23\n\nPython implementation: CPython\nPython version       : 3.9.10\nIPython version      : 8.2.0\n\ngeopandas: 0.10.2\ngeosnap  : 0.10.0+6.g592f2ee57e05.dirty\n\n\n\nAs a package focused on “neighborhoods”, much of the functionality in geosnap is organized around the concept of ‘endogenous’ neighborhoods. That is, it takes a classical perspective on neighborhood formation: a ‘neighborhood’ is defined loosely by its social composition, and the dynamics of residential mobility mean that these neighborhoods can grow, shrink, or transition entirely.\nBut two alternative concepts of “neighborhood” are also worth considering. The first, posited by social scientists, is that each person or household can be conceptialized as residing in its own neighborhood which extends outward from the person’s household until some threshold distance. This neighborhood represents the boundary inside which we might expect some social interaction to occur with one’s ‘neighbors’. The second is a normative concept advocated by architects, urban designers, and planners (arguably still the goal for new urbanists): that a neighborhood is a discrete pocket of infrastructure organized as a small, self-contained economic unit. A common shorthand today is the 20 minute neighborhood.\n\nhttps://upload.wikimedia.org/wikipedia/en/e/e3/New_York_Regional_Survey%2C_Vol_7.jpg?20170410025533\nThe difference between these two perspectives is really what defines the origin of the neighborhood (the ‘town center’ or the person’s home), and whether ‘neighborhood’ is universal to all neighbors or unique for each resident. Both of them rely abstractly on the concept of an isochrone: the set of destinations accessible within a specified travel budget. Defining an isochrone is a network routing problem, but its spatial representation is usually given as a polygon that covers the set of locations. That polygon is also sometimes called a walkshed (or *travel shed, depending on the particular mode). For the person at the center of the isochrone, whose “neighborhood” the isochrone represents, the polygon is sometimes conceptualized as an “egohood” or “bespoke neighborhood”.\nThe trouble with generating isochrones is twofold. First, they are computationally intensive to create. You need to know the shortest path from an origin to all other possible destinations inside the travel threshold, and depending on the density of the network, this can scale masssively. Second, they are not straightforward to present cartographically/visually. The set of destinations reachable within the threshold is technically a set of points. If you’re constrained to a network, then we can usually assume that you also have access to potential locations between discrete destinations. For example if you’re walking along the sidewalk, you can stop at any house along the block until you reach your threshold distance. But sometimes that’s not the case. If you walk to a subway station, you can stop anywhere along the walk–until you get into the subway, then you are stuck traveling in one direction until you reach another station, then you get freedom of mobility again.\nThe latter case is particularly difficult to represent because it doesnt create a “valid” polygon… there’s a single polygon in the pre-transit zone, then the “accessible zone” collapses to a line (or nothing at all?) before opening back up into a polygon again. Like a barbell. If you take the simple route and just draw a convex hull around the accessible destinations, it will fail to collapse along the line, giving the false impression of much more ‘access’ than is realistic.\nBut then again, sometimes these off-network spaces are actually traversable. If two network nodes inside the travel threshold are separated by a park, then you can just walk through the park and that should be included in the visualization. If they are separated by a harbor or a mountain, you definitely can’t walk through (ok, maybe you could get through, but not without sacrificing a bit of speed at the very least).\nTo handle these issues, the isochrones implemented in geosnap take a straightforward approach, achieving a good balance between accuracy and speed. Specifically, we tackle the problem in two stages: first, we use pandana to generate the set nodes accessible from [a set of] destination[s]. Then we wrap an alpha shape around those destinations to create a tightly-fitted polygon. The alpha shape algorithm implemented in libpysal is also blazing fast, so the approach has worked quite well in all of our applications\n\nfrom geosnap.analyze import compute_travel_cost_adjlist, isochrone, isochrones # a singular and a plural\nfrom geosnap.io import get_acs\nfrom geosnap import DataStore\n\n\nimport pandana as pdna\nimport geopandas as gpd\n\n\ndatasets = DataStore()\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/_data.py:66: UserWarning: The geosnap data storage class is provided for convenience only. The geosnap developers make no promises regarding data quality, consistency, or availability, nor are they responsible for any use/misuse of the data. The end-user is responsible for any and all analyses or applications created with the package.\n  warn(\n\n\nTo generate a routable network, use pandana or urbanaccess. Alternatively, you can download one of the metropolitan-scale pedestrian networks for the U.S. from geosnap’s quilt bucket. The files are named for each CBSA fips code and extend 8km beyond the metro region’s borders to help mitigate edge effects. Here, we’ll use the quilt version from the San Diego region.\n\nsd_network = pdna.Network.from_hdf5(\"../../geosnap_data/metro_networks_8k/41740.h5\")\n\nGenerating contraction hierarchies with 10 threads.\nSetting CH node vector of size 332554\nSetting CH edge vector of size 522484\nRange graph removed 143094 edges of 1044968\n. 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n\n\nTo generate a travel isochrone, we have to specify an origin node on the network. For demonstration purposes, we can randomly select an origin from the network’s nodes_df dataframe (or choose a pre-selected example). To get the nodes for a specific set of origins, you can use pandana’s get_node_ids function\n\nfrom random import sample\n\n\nrandom_origin = sample(sd_network.nodes_df.index.unique().tolist(),1)[0]\n\n\nrandom_origin\n\n5534356004\n\n\n\nexample_origin = 1985327805\n\nNike, er… this study says that the average person walks about a mile in 20 minutes, so we can define the 20-minute neighborhood for a given household as the 1-mile walkshed from that house. To simplify the computation a little, we say that each house “exists” at it’s nearest intersection\n(this is the abstraction pandana typically uses to simplify the problem when using data from OpenStreetMap. There’s nothing prohibiting you from creating an even more realistic version with nodes for each residence, as long as you’re comfortable creating the Network)\n\n%%time\niso = isochrone(example_origin, sd_network, threshold=1600 ) # network is expressed in meters\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  origins.centroid.x, origins.centroid.y\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  origins.centroid.x, origins.centroid.y\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:45: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  destinations.centroid.x, destinations.centroid.y\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:45: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  destinations.centroid.x, destinations.centroid.y\n\n\n\n\n\nCPU times: user 7.85 s, sys: 446 ms, total: 8.3 s\nWall time: 3.28 s\n\n\n\niso.explore()\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nWe can also look at how the isochrone or bespoke neighborhood changes size and shape as we consider alternative travel thresholds. Because of the underlying network configuration, changing the threshold often results in some areas of the “neighborhood” changing more than others\n\n%%time\niso_multiple = isochrone(example_origin, sd_network, threshold=[1600, 2400, 3200]  )\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  origins.centroid.x, origins.centroid.y\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  origins.centroid.x, origins.centroid.y\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:45: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  destinations.centroid.x, destinations.centroid.y\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:45: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  destinations.centroid.x, destinations.centroid.y\n\n\n\n\n\nCPU times: user 7.65 s, sys: 250 ms, total: 7.9 s\nWall time: 2.61 s\n\n\n\niso_multiple.explore('distance', cmap='Blues_r', style_kwds={'fillOpacity':0.5})\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nIn this example it’s easy to see how the road network topology makes it easier to travel in some directions more than others. Greenspace squeezes the western portion of the 1600m (20 min) isochrone into a horizontal pattern along Calle del Cerro, but the 2400m (30 minute) isochrone opens north-south tavel again along Avienda Pico, providing access to two other pockets of development, including San Clemente High School\nWe can also compare the network-based isochrone to the as-the-crow-flies approximation given by a euclidean buffer. If we didn’t have access to network data, this would be our best estimate of the shape and extent of the 20-minute neighborhood.\n\n# convert the node into a Point and buffer it 1600m\n\nexample_point = gpd.GeoDataFrame(sd_network.nodes_df.loc[example_origin]).T\nexample_point.crs=4326\nplanar_iso = example_point.to_crs(example_point.estimate_utm_crs()).buffer(1600)\n\n\n# plot the buffer and isochrone on the same map\n\nm = planar_iso.to_crs(4326).explore()\niso.explore(m=m)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nObviously from this depiction, network-constrained travel is very different from a euclidean approximation. That’s especially true in places with irregular networks or topography considerations (like much of California)"
  },
  {
    "objectID": "isochrone_example.html#isochrones-for-specified-locations",
    "href": "isochrone_example.html#isochrones-for-specified-locations",
    "title": "8  Egohoods and Isochrones",
    "section": "8.2 Isochrones for Specified Locations",
    "text": "8.2 Isochrones for Specified Locations\nthe isochrones function calculates several isochrones simultaneously, given a set of input destinations. For example we could look at the 20-minute neighborhood for schools in San Diego county.\n\nfrom geosnap.io import get_nces\n\n\nisochrones?\n\n\nSignature: isochrones(origins, threshold, network, matrix=None, network_crs=4326)\nDocstring:\nCreate travel isochrones for several origins simultaneously\nParameters\n----------\norigins : geopandas.GeoDataFrame\n    a geodataframe containing the locations of origin point features\nnetwork : pandana.Network\n    pandana Network instance for calculating the shortest path isochrone for each origin feature\nthreshold: float\n    maximum travel distance to define the isochrone, measured in the same units as edges_df\n    in the pandana.Network object. If the network was created with pandana this is usually meters;\n    if it was created with urbanaccess this is usually travel time in minutes.\nmatrix: pandas dataframe (optional)\n    precalculated adjacency list dataframe created with `compute_travel_adjlist`\nnetwork_crs : str, int, pyproj.CRS (optional)\n    the coordinate system used to store x and y coordinates in the passed pandana network.\n    If the network was created with pandana or urbanaccess this is nearly always 4326.\nReturns\n-------\nGeoPandas.DataFrame\n    polygon geometries with the isochrones for each origin point feature\nFile:      ~/Dropbox/projects/geosnap/geosnap/analyze/network.py\nType:      function\n\n\n\n\n\n# same as county fips 06073 in this case, but use metro fips for consistency with network\nsd = get_acs(datasets, msa_fips='41740', level='bg', years=[2019])\n\n\nsd.plot()\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\n\nschools = get_nces(datasets, dataset='schools')\n\n\nsd_schools = schools[schools.to_crs(sd.crs).intersects(sd.unary_union)]\n\n\nsd_schools.head()\n\n\n\n\n\n\n\n\nNCESSCH\nNAME\nOPSTFIPS\nLSTREE\nLCITY\nLSTATE\nLZIP\nLZIP4\nSTFIP15\nCNTY15\n...\nCBSATYPE15\nCSA15\nNMCSA15\nNECTA15\nNMNECTA15\nCD15\nSLDL15\nSLDU15\ngeometry\nyear\n\n\n\n\n5895\n060004205341\nWarner Junior/Senior High\n06\n30951 Highway 79\nWarner Springs\nCA\n92086\nM\n06\n06073\n...\n1\nN\nN\nN\nN\n0650\n071\n038\nPOINT (-116.64292 33.27525)\n1516\n\n\n5896\n060004206527\nSan Jose Valley Continuation Hig\n06\n30951 Highway 79\nWarner Springs\nCA\n92086\nM\n06\n06073\n...\n1\nN\nN\nN\nN\n0650\n071\n038\nPOINT (-116.64292 33.27525)\n1516\n\n\n5897\n060004206844\nWarner Elementary\n06\n30951 Highway 79\nWarner Springs\nCA\n92086\n0008\n06\n06073\n...\n1\nN\nN\nN\nN\n0650\n071\n038\nPOINT (-116.64292 33.27525)\n1516\n\n\n5898\n060004210387\nAll Tribes Charter\n06\n34320 Valley Center Rd.\nValley Center\nCA\n92082\n6046\n06\n06073\n...\n1\nN\nN\nN\nN\n0650\n075\n038\nPOINT (-116.95367 33.27796)\n1516\n\n\n5899\n060004212735\nAll Tribes Elementary Charter\n06\n34320 Valley Center Rd.\nValley Center\nCA\n92082\n6046\n06\n06073\n...\n1\nN\nN\nN\nN\n0650\n075\n038\nPOINT (-116.95367 33.27796)\n1516\n\n\n\n\n5 rows × 26 columns\n\n\n\n\nsd_schools.plot()\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\n\n# randomly sample 25 schools and compute their walksheds\n\nschool_neighborhoods = isochrones(origins=sd_schools.sample(25), network=sd_network, threshold=1600,)\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  origins.centroid.x, origins.centroid.y\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  origins.centroid.x, origins.centroid.y\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:45: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  destinations.centroid.x, destinations.centroid.y\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:45: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  destinations.centroid.x, destinations.centroid.y\n\n\n\n\n\n\nschool_neighborhoods.explore()\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nIf we adopt the “neighborhood unit” perspective, it might be reasonable to put a school at the center of the neihborhood, as it would provide equitable access to all residents. In that case, these are your neighborhoods"
  },
  {
    "objectID": "isochrone_example.html#network-based-travel-cost-matrix",
    "href": "isochrone_example.html#network-based-travel-cost-matrix",
    "title": "8  Egohoods and Isochrones",
    "section": "8.3 Network-Based Travel Cost Matrix",
    "text": "8.3 Network-Based Travel Cost Matrix\nIn some cases, the isochrone is less interesting than the interaction structure it implies; Often in social science research, the isochrone is an abstract representation of the concept of distance decay. Social interactions are are more frequent among people who are close to one another, and the frequency of those interactions decreases with distance (in the isochrone case, the ‘neighborhood’ is a discrete container, in others a decay function is applied inside the isochrone to allow for a “continuous neighborhood”).\nThus, in some research contexts, the isochrone itself is less useful than capturing the shortest-path network distance from a set of origins to a set of destinations (this can later be used as a spatial weights matrix or an input to accessibility analysis). The pandana library is fantastic at finding shortest-paths through large networks, but it’s designed primarily for creating network aggregation queries rather than generating the dense all-pairs travel cost matrix–that’s what this function generates.\nUnlike the isochrone and isochrones functions which compute the shortest network path from each input origin to every destination node in the network, the compute_travel_cost_adjlist function only computes paths between the specified origins and destinations, reducing the computational burden for large networks (i.e. compute_travel_cost_adjlist allows you to subset the destination set also) .\n(Under the hood, the isochrone functions use compute travel_cost_adjlist function to compute the path between the set of origins and all destination nodes in the network (i.e. subsetting only the origins, not the destinations). If you want to generate isochrones really fast e.g. in a web application, or do repeated queries for some other project, it’s possible to compute and store the dense the all-pairs shortest-cost travel matrix ahead of time. Note this is happening at the intersection level, so for a metro the size of san diego, this is a massive problem, even with pandana’s speed… In that case, you can pass the precomputed matrix directly to the isochrones function\n\ncompute_travel_cost_adjlist?\n\n\nSignature:\ncompute_travel_cost_adjlist(\n    origins,\n    destinations,\n    network,\n    index_orig=None,\n    index_dest=None,\n)\nDocstring:\nGenerate travel cost adjacency list.\nParameters\n----------\norigins : geopandas.GeoDataFrame\n    a geodataframe containing the locations of origin features\ndestinations : geopandas.GeoDataFrame\n    a geodataframe containing the locations of destination features\nnetwork : pandana.Network\n    pandana Network instance for calculating the shortest path between origins and destinations\nindex_orig : str, optional\n    Column on the origins dataframe the defines unique units to be used as the origins id\n    on the resulting dataframe. If not set, each unit will be assigned the index from its\n    associated node_id on the network\nindex_dest : str, optional\n    Column on the destinations dataframe the defines unique units to be used as the destinations id\n    on the resulting dataframe. If not set, each unit will be assigned the index from its\n    associated node_id on the network\nReturns\n-------\npandas.DataFrame\n    pandas DataFrame containing the shortest-cost distance from each origin feature to each destination feature\nFile:      ~/Dropbox/projects/geosnap/geosnap/analyze/network.py\nType:      function\n\n\n\n\nWe can trim the problem down by passing a geodataframe of origins/destinations like blockgroups or tracts to make the problem a bit smaller (\\(n_{blockgroups}^2\\) instead of \\(n_{intersections}^2\\))\n\nsd_adj = compute_travel_cost_adjlist(sd, sd, sd_network, index_dest='geoid', index_orig='geoid')\n\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  origins.centroid.x, origins.centroid.y\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  origins.centroid.x, origins.centroid.y\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:45: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  destinations.centroid.x, destinations.centroid.y\n/Users/knaaptime/Dropbox/projects/geosnap/geosnap/analyze/network.py:45: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n\n  destinations.centroid.x, destinations.centroid.y\n\n\n\n\n\nThe sd_adj dataframe is an adjacency list representation of the shortest-path cost between each block-group centroid in San Diego county\n\nsd_adj\n\n\n\n\n\n\n\n\norigin\ndestination\ncost\n\n\n\n\n0\n060730001001\n060730001001\n0.000\n\n\n1\n060730001001\n060730001002\n987.566\n\n\n2\n060730001001\n060730002011\n1221.944\n\n\n3\n060730001001\n060730002021\n2208.548\n\n\n4\n060730001001\n060730002022\n1465.891\n\n\n...\n...\n...\n...\n\n\n1790\n060739901000\n060730220002\n40466.678\n\n\n1791\n060739901000\n060730221001\n23566.234\n\n\n1792\n060739901000\n060730221002\n21198.103\n\n\n1793\n060739901000\n060730221003\n18928.505\n\n\n1794\n060739901000\n060739901000\n0.000\n\n\n\n\n3222025 rows × 3 columns"
  },
  {
    "objectID": "isochrone_example.html#extensions",
    "href": "isochrone_example.html#extensions",
    "title": "8  Egohoods and Isochrones",
    "section": "8.4 Extensions",
    "text": "8.4 Extensions\nOne nice thing about this implementation is that it’s indifferent to the structure of the input network. It could be pedestrian-based (which is the most common), but you could also use urbanaccess to create a multimodel network by combining OSM and GTFS data.\nRunning the above functions on that multimodal network would give a good sense of “baseline” accessibility in a study region. An interested researcher could then make some changes to the GTFS network, say, by increasing bus frequency along a given corridor, then create another combined network and compare results. Who would benefit from such a change, and what might be the net costs?\nAnd thus, the seeds of open and reproducible scenario planning have been sown :)"
  }
]